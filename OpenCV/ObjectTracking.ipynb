{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple object tracking with OpenCV\n",
    "### Object tracking is the process of:\n",
    " - Taking an initial set of object detections (such as an input set of bounding box coordinates)\n",
    " - Creating a unique ID for each of the initial detections\n",
    " - And then tracking each of the objects as they move around frames in a video, maintaining the assignment of unique IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, object tracking allows us to apply a unique ID to each tracked object, making it possible for us to count unique objects in a video. Object tracking is paramount to building a person counter (which we’ll do later in this series).\n",
    "\n",
    "An ideal object tracking algorithm will:\n",
    " - Only require the object detection phase once (i.e., when the object is initially detected)\n",
    " - Will be extremely fast — much faster than running the actual object detector itself\n",
    " - Be able to handle when the tracked object “disappears” or moves outside the boundaries of the video frame\n",
    " - Be robust to occlusion\n",
    " - Be able to pick up objects it has “lost” in between frames\n",
    " \n",
    "This is a tall order for any computer vision or image processing algorithm and there are a variety of tricks we can play to help improve our object trackers.\n",
    "\n",
    "But before we can build such a robust method we first need to study the fundamentals of object tracking.\n",
    "\n",
    "In today’s blog post, you will learn how to implement centroid tracking with OpenCV, an easy to understand, yet highly effective tracking algorithm.\n",
    "\n",
    "In future posts in this object tracking series, I’ll start going into more advanced kernel-based and correlation-based tracking algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object tracking algorithm is called centroid tracking as it relies on the Euclidean distance between \n",
    " - (1) existing object centroids (i.e., objects the centroid tracker has already seen before) and \n",
    " - (2) new object centroids between subsequent frames in a video.\n",
    " \n",
    "We’ll review the centroid algorithm in more depth in the following section. From there we’ll implement a Python class to contain our centroid tracking algorithm and then create a Python script to actually run the object tracker and apply it to input videos.\n",
    "\n",
    "Finally, we’ll run our object tracker and examine the results, noting both the positives and the drawbacks of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The centroid tracking algorithm\n",
    "The centroid tracking algorithm is a multi-step process. We will review each of the tracking steps in this section.\n",
    "\n",
    "## Step #1: Accept bounding box coordinates and compute centroids\n",
    "\n",
    "The centroid tracking algorithm assumes that we are passing in a set of bounding box (x, y)-coordinates for each detected object in every single frame.\n",
    "\n",
    "These bounding boxes can be produced by any type of object detector you would like (color thresholding + contour extraction, Haar cascades, HOG + Linear SVM, SSDs, Faster R-CNNs, etc.), provided that they are computed for every frame in the video.\n",
    "\n",
    "Once we have the bounding box coordinates we must compute the “centroid”, or more simply, the center (x, y)-coordinates of the bounding box. Figure 1 above demonstrates accepting a set of bounding box coordinates and computing the centroid.\n",
    "\n",
    "Since these are the first initial set of bounding boxes presented to our algorithm we will assign them unique IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #2: Compute Euclidean distance between new bounding boxes and existing objects\n",
    "\n",
    "For every subsequent frame in our video stream we apply Step #1 of computing object centroids; however, instead of assigning a new unique ID to each detected object (which would defeat the purpose of object tracking), we first need to determine if we can associate the new object centroids (yellow) with the old object centroids (purple). To accomplish this process, we compute the Euclidean distance (highlighted with green arrows) between each pair of existing object centroids and input object centroids.\n",
    "\n",
    "From Figure 2 you can see that we have this time detected three objects in our image. The two pairs that are close together are two existing objects.\n",
    "\n",
    "We then compute the Euclidean distances between each pair of original centroids (yellow) and new centroids (purple). But how do we use the Euclidean distances between these points to actually match them and associate them?\n",
    "\n",
    "The answer is in Step #3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #3: Update (x, y)-coordinates of existing objects\n",
    "\n",
    "The primary assumption of the centroid tracking algorithm is that a given object will potentially move in between subsequent frames, but the distance between the centroids for frames $F_t$ and $F_{t + 1}$ will be smaller than all other distances between objects.\n",
    "\n",
    "Therefore, if we choose to associate centroids with minimum distances between subsequent frames we can build our object tracker.\n",
    "\n",
    "In Figure 3 you can see how our centroid tracker algorithm chooses to associate centroids that minimize their respective Euclidean distances.\n",
    "\n",
    "But what about the lonely point in the bottom-left?\n",
    "\n",
    "It didn’t get associated with anything — what do we do with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #4: Register new objects\n",
    "\n",
    "In the event that there are more input detections than existing objects being tracked, we need to register the new object. “Registering” simply means that we are adding the new object to our list of tracked objects by:\n",
    "\n",
    " - Assigning it a new object ID\n",
    " - Storing the centroid of the bounding box coordinates for that object\n",
    " \n",
    "We can then go back to Step #2 and repeat the pipeline of steps for every frame in our video stream.\n",
    "\n",
    "Figure 4 demonstrates the process of using the minimum Euclidean distances to associate existing object IDs and then registering a new object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5: Deregister old objects\n",
    "Any reasonable object tracking algorithm needs to be able to handle when an object has been lost, disappeared, or left the field of view.\n",
    "\n",
    "Exactly how you handle these situations is really dependent on where your object tracker is meant to be deployed, but for this implementation, we will deregister old objects when they cannot be matched to any existing objects for a total of N subsequent frames."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ tree --dirsfirst\n",
    ".\n",
    "├── pyimagesearch\n",
    "│   ├── __init__.py\n",
    "│   └── centroidtracker.py\n",
    "├── object_tracker.py\n",
    "├── deploy.prototxt\n",
    "└── res10_300x300_ssd_iter_140000.caffemodel\n",
    " \n",
    "1 directory, 5 files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
