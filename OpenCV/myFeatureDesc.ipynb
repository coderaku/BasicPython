{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV: Feature Detection and Description\n",
    "## Harris Corner Detection\n",
    "\n",
    "### Goal\n",
    "\n",
    "In this chapter,\n",
    "\n",
    "- We will understand the concepts behind Harris Corner Detection.\n",
    "- We will see the functions: cv2.cornerHarris(), cv2.cornerSubPix()\n",
    "\n",
    "### Theory\n",
    "\n",
    "In last chapter, we saw that corners are regions in the image with large variation in intensity in all the directions. One early attempt to find these corners was done by Chris Harris & Mike Stephens in their paper *A Combined Corner and Edge Detector* in 1988, so now it is called Harris Corner Detector. He took this simple idea to a mathematical form. It basically finds the difference in intensity for a displacement of $(u,v)$ in all directions. This is expressed as below\n",
    "\n",
    "![Image](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/math/1948f2850c912ce3394b61ba99b546f1bf7a6adc.png)\n",
    "\n",
    "Window function is either a rectangular window or gaussian window which gives weights to pixels underneath.\n",
    "\n",
    "We have to maximize this function $E(u,v)$ for corner detection. That means, we have to maximize the second term. Applying Taylor Expansion to above equation and using some mathematical steps (please refer any standard text books you like for full derivation), we get the final equation as:\n",
    "\n",
    "![Image](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/math/3aea48f44ebcc36dda8055c842e209d8886d7a80.png)\n",
    "\n",
    "where\n",
    "\n",
    "![Image](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/math/a33b6840bcc7c240425581fe5e39e58d868f9893.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $I_x$ and $I_y$ are image derivatives in $x$ and $y$ directions respectively. (Can be easily found out using **cv2.Sobel()**).\n",
    "\n",
    "Then comes the main part. After this, they created a score, basically an equation, which will determine if a window can contain a corner or not.\n",
    "\n",
    "![Image](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/math/8499c5fd1fb4572f17432043824392ba87e027e6.png)\n",
    "\n",
    "where\n",
    "\n",
    "- $det(M)=\\lambda_1\\lambda_2$\n",
    "- $trace(M)=\\lambda_1+\\lambda_2$\n",
    "- $\\lambda_1$ and $\\lambda_2$ are the eigen values of $M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the values of these eigen values decide whether a region is corner, edge or flat.\n",
    "\n",
    "- When $|R|$ is small, which happens when $\\lambda_1$ and $\\lambda_2$ are small, the region is flat.\n",
    "- When $R<0$, which happens when $\\lambda_1 \\gg \\lambda_2$ or vice versa, the region is edge.\n",
    "- When $R$ is large, which happens when $\\lambda_1$ and $\\lambda_2$ are large and $\\lambda_1 \\sim \\lambda_2$, the region is a corner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be represented in a nice picture as follows:\n",
    "\n",
    "![Image](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/harris_region.jpg)\n",
    "\n",
    "So the result of Harris Corner Detection is a grayscale image with these scores. Thresholding for a suitable give you the corners in the image. We will do it with a simple image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harris Corner Detector in OpenCV\n",
    "OpenCV has the function *cv2.cornerHarris()* for this purpose. Its arguments are :\n",
    "\n",
    "- **img** - Input image, it should be grayscale and float32 type.\n",
    "- **blockSize** - It is the size of neighbourhood considered for corner detection\n",
    "- **ksize** - Aperture parameter of Sobel derivative used.\n",
    "- **k** - Harris detector free parameter in the equation.\n",
    "\n",
    "See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "filename = 'Images/chessboard.jpg'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to gray image\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('dst',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner with SubPixel Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Images/chessboard.jpg'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find Harris corners\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "dst = cv2.dilate(dst,None)\n",
    "ret, dst = cv2.threshold(dst,0.01*dst.max(),255,0)\n",
    "dst = np.uint8(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find centroids\n",
    "ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the criteria to stop and refine the corners\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "corners = cv2.cornerSubPix(gray,np.float32(centroids),(5,5),(-1,-1),criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now draw them\n",
    "res = np.hstack((centroids,corners))\n",
    "res = np.int0(res)\n",
    "img[res[:,1],res[:,0]]=[0,0,255]\n",
    "img[res[:,3],res[:,2]] = [0,255,0]\n",
    "cv2.imwrite('subpixel5.png',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shi-Tomasi Corner Detector & Good Features to Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/blox.jpg')\n",
    "print(img.shape)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = cv2.goodFeaturesToTrack(gray,2,0.11,1)\n",
    "corners = np.int0(corners)\n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(img,(x,y),3,255,-1)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
